## <center>scrapy框架使用selenium抓取数据</center>

> 之前我们介绍过抓取动态网站数据,常用的技术有直接分析`ajax`请求,我们直接请求接口,还有一种方式就是直接模拟浏览器请求数据,本章节中介绍在`scrapy`中使用`selenium`模拟浏览器请求爬取数据.

### 一、在`scrapy`中集成`selenium`的步骤

* 1、定义一个下载中间件

  ```py
  from selenium import webdriver
  from scrapy.http import HtmlResponse

  class SeleniumMiddleware(object):
      def __init__(self):
          super(SeleniumMiddleware, self).__init__()
          self.browser = webdriver.Chrome()

      def process_request(self, request, spider):
          self.browser.implicitly_wait(5)
          self.browser.get(request.url)
          print('你访问的网站:{0}'.format(request.url))
          return HtmlResponse(url=self.browser.current_url, body=self.browser.page_source, encoding="utf-8", request=request)

  ```

* 2、在`settings.py`中注册激活
