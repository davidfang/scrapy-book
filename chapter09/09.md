## <center>scrapy框架使用selenium抓取数据</center>

> 之前我们介绍过抓取动态网站数据,常用的技术有直接分析`ajax`请求,我们直接请求接口,还有一种方式就是直接模拟浏览器请求数据,本章节中介绍在`scrapy`中使用`selenium`模拟浏览器请求爬取数据.

### 一、在`scrapy`中集成`selenium`的步骤

* 1、定义一个下载中间件

  ```py
  from selenium import webdriver
  from scrapy.http import HtmlResponse

  class SeleniumMiddleware(object):
      def __init__(self):
          super(SeleniumMiddleware, self).__init__()
          self.browser = webdriver.Chrome()

      def process_request(self, request, spider):
          self.browser.implicitly_wait(5)
          self.browser.get(request.url)
          print('你访问的网站:{0}'.format(request.url))
          return HtmlResponse(url=self.browser.current_url, body=self.browser.page_source, encoding="utf-8", request=request)

  ```

* 2、在`settings.py`中注册激活

### 二、结合信号量来实现抓取数据后就关闭浏览器

* 1、`spider`的代码

  ```py
  import scrapy
  from selenium import webdriver
  from scrapy import signals
  from scrapy.xlib.pydispatch import dispatcher

  class TianmaoSpider(scrapy.Spider):
      name = 'tianmao'
      allowed_domains = ['tmall.com']
      start_urls = [
          'https://list.tmall.com/search_product.htm?q=%CC%FA%B9%F8&type=p&vmarket=&spm=875.7931836%2FB.a2227oh.d100&from=mallfp..pc_1_searchbutton']

      def __init__(self):
          super(TianmaoSpider, self).__init__()
          # 创建一个browser的对象
          self.browser = webdriver.Chrome()
          # dispatcher.connect()信号分发器，第一个参数信号触发函数，第二个参数是触发信号，signals.spider_closed是爬虫结束信号
          dispatcher.connect(self.spider_close, signals.spider_closed)

      def parse(self, response):
          print(response.text)

      def spider_close(self, spider):
          print('爬虫结束')
          self.browser.quit()
  ```

* 2、在中间件中使用`spider`中创建的`browser`对象,并返回数据

  ```py
  from scrapy.http import HtmlResponse

  class SeleniumMiddleWare(object):
      """
      使用selenium访问网站
      """

      def process_request(self, request, spider):
          if spider.name == 'tianmao':
              spider.browser.get(request.url)
              # 这个地方可以根据自己抓取的网站设置隐式等待,等待那个节点出现
              spider.browser.implicitly_wait(5)
              return HtmlResponse(url=spider.browser.current_url, body=spider.browser.page_source, encoding='utf8', request=request)
  ```

* 3、`settings.py`文件中注册
