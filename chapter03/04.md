### <center>Beautiful Soup的使用</center>

> 关于[Beautiful Soup官网地址](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/)

### 一、使用步骤

* 1、安装包

  ```py
  pip3 install beautifulsoup4
  ```

* 2、简单的使用

  ```py
  html_doc = """
      <html>
      <head>
      <title>博客</title>
      </head>
      <body>
      <p>分享 Android 技术，也关注 Python 等热门技术。</p>
      <p>写博客的初衷：总结经验，记录自己的成长。</p>
      <p>你必须足够的努力，才能看起来毫不费力！专注！精致！
      </p>
      <p class="Blog"><a href="http://wuxiaolong.me/">WuXiaolong's blog</a></p>
      <p class="WeChat"><a href="https://open.weixin.qq.com/qr/code?username=MrWuXiaolong">公众号：吴小龙同学</a> </p>
      <p class="GitHub"><a href="http://example.com/tillie" class="sister" id="link3">GitHub</a></p>
      </body>
      </html>   
      """

  soup = BeautifulSoup(html_doc, "html5lib") # html5lib是解析器
  soup.find('p') # 找到第一个p标签
  ```

### 二、几种解析器的区别

|解析器|使用方法|优势|劣势|
|---|---|---|---|
|python标准库|BeautifulSoup(html_doc, "html.parser")|Python的内置标准库<br/>执行速度适中<br/>文档容错能力强|Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差<br/><font color="#f00">默认解析器(不指定的时候就是这个)</font>|
|lxml HTML解析器|BeautifulSoup(html_doc, "lxml")|速度快<br/>文档容错能力强|需要安装C语言库<font color="#f00">(推荐使用)</font>|
|lxml XML解析器|BeautifulSoup(html_doc, ['lxml', 'xml'])|速度快<br/>唯一支持XML的解析器|需要安装C语言库|
|html5lib|BeautifulSoup(html_doc, "html5lib")|最好的容错性<br />以浏览器的方式解析文档<br />生成HTML5格式的文档|速度慢<br/>不依赖外部扩展<br/><font color="#f00">在html标签不规范的时候使用</font>|

### 三、基本使用

* 1、基本的`html`结构

  ```py
  from bs4 import BeautifulSoup

  html_doc = """
  <ul>
      <li class="odd"><a href="aa.html" data-id="1">链接一</a><span>第一个</span></li>
      <li class="even"><a href="bb.html" data-id="2">链接二</a><span>第二个</span></li>
      <li class="odd"><a href="cc.html" data-id="3">链接三</a><span>第三个</span></li>
      <li class="even"><a href="dd.html" data-id="4">链接四</a><span>第四个</span></li>
      <li class="odd"><a href="ee.html" data-id="5">链接五</a><span>第五个</span></li>
  </ul>
  """

  soup = BeautifulSoup(html_doc, 'lxml')
  ```
* 2、`find(标签)`查找第一个匹配的元素
* 3、`find_all(标签)`查找全部的标签
* 4、使用`name`获取查找的标签名

  ```py
  print(soup.find('a').name)
  ```
* 5、使用`attrs`获取`attr`属性

  ```py
  print(soup.find('a').attrs)
  ```

* 6、使用`has_attr`判断一个节点是否有该属性

  ```py
  print(soup.find('li').has_attr('class'))
  ```

* 7、使用`get_text()`获取文本内容

  ```py
  print(soup.find('li').get_text())
  ```

* 8、使用`is_empty_element`判断标签是否为空

  ```py
  print(soup.find('li').is_empty_element)
  ```

### 三、查找节点的案例(使用的`html`还是上一章节的)

* 1、获取全部的`tr`

  ```py
  trs = soup.find_all('tr')
      for tr in trs:
          print(tr)
          print('-' * 30)
  ```

* 2、获取第二个`tr`

  ```py
  trs = soup.find_all('tr')[1:2]
      for tr in trs:
          print(tr)
          print('-' * 30)
  # 或者使用limit
  trs = soup.find_all('tr', limit=2)[1]
  print(trs)
  ```

* 3、获取`class="even"`的

  ```py
  trs = soup.find_all('tr', class_="even")
      for tr in trs:
          print(tr)
          print('-' * 30)
  ```

* 4、使用`attrs`的方式来写过滤条件**<font color="#f00">推荐写法,可以将一切都属性都写在里面</font>**

  ```py
  trs = soup.find_all('tr', attrs={'class': 'even'})

  for tr in trs:
      print(tr)
      print('*' * 30)
  ```

* 5、获取全部`a`标签的`href`值

  ```py
  a_link_list = soup.find_all('a')
  for item in a_link_list:
      print(item.attrs['href'])
  ```

* 6、获取全部的职业信息

  ```py
  trs = soup.find_all('tr')
  for tr in trs:
      tds = tr.find('td')
      print(tds.find('a').string)
      # 或者使用get_text()
      # pring(tds.find('a').get_text())
  ```

* 7、综合案例(提取全部的信息,list返回)

  ```py
  position = []

  trs = soup.find_all('tr')

  for tr in trs:
      tds = tr.find_all('td')
      post = {}

      title = tds[0].find('a').get_text()
      type = tds[1].get_text()
      num = tds[2].get_text()
      city = tds[3].get_text()
      public_time = tds[4].get_text()

      post['title'] = title
      post['type'] = type
      post['num'] = num
      post['city'] = city
      post['public_time'] = public_time

      position.append(post)

  print(position)
  ```

### 五、关于提取文本信息的几个对比

* `string`: 获取某个标签下的非标签字符串
* `strings`: 获取某个标签下子孙非标签的字符串
* `stripped_strings`: 获取某个标签下的子孙非标签字符串,并且会去除空格
* `get_text()`:获取某个标签下子孙非标签字符