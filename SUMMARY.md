# Summary

* [基本介绍](README.md)
* [第一章:urllib模块的使用](chapter01/0.md)
  * [1.常用方法的介绍](chapter01/01.md)
  * [2.request常用方法](chapter01/02.md)
  * [3.关于cookie的认识](chapter01/03.md)
* [第二章:requests请求库的使用](chapter02/0.md)
  * [1.基本的使用](chapter02/01.md)
  * [2.requests的高级使用](chapter02/02.md)
  * [3.模拟用户登录](chapter02/03.md)

* [第三章:解析库的使用](chapter03/0.md)
  * [1.xpath语法的介绍](chapter03/01.md)
  * [2.lxml库的使用](chapter03/02.md)
  * [3.xpath和lxml结合起来使用](chapter03/03.md)
  * [4.使用xpath和lxml爬取伯乐在线](chapter03/04.md)
  * [5.Beautiful Soup的使用](chapter03/05.md)
  * [6.css选择器](chapter03/06.md)
  * [7.使用bs4爬取获取贵州农产品](chapter03/07.md)
  * [8.正则的使用](chapter03/08.md)

* [第四章:数据存储](chapter04/0.md)
  * [1.关于文件的写入](chapter04/01.md)
  * [2.python操作csv文件](chapter04/02.md)
  * [3.数据存储到mysql数据库中](chapter04/03.md)
  * [4.数据存储到mongodb数据库中](chapter04/04.md)
  * [5.完整的下载数据存储的代码](chapter04/05.md)
  * [6.使用urllib模块方式下载图片](chapter04/06.md)
  * [7.使用写文件的方式下载图片](chapter04/07.md)

* [第五章:多线程爬虫](chapter05/0.md)
  * [1.关于多线程的回顾](chapter05/01.md)
  * [2.多线程下载农产品产品存储到本地](chapter05/02.md)
  * [3.使用多线程下载图片](chapter05/03.md)

* [第六章:动态网站的抓取](chapter06/0.md)
  * [1.动态网站的爬取的策略](chapter06/01.md)
  * [2.使用json方法爬取动态网站](chapter06/02.md)
  * [3.关于Selenium的基本介绍及环境的安装](chapter06/03.md)
  * [4.selenium的查找元素](chapter06/04.md)
  * [5.selenium获取节点信息](chapter06/05.md)
  * [6.selenium节点操作及操作表单](chapter06/06.md)
  * [7.selenium的等待认识](chapter06/07.md)
  * [8.selenium的cookie、设置代理、异常](chapter06/08.md)
  * [9.关于无界面浏览器的使用](chapter06/09.md)
  * [10.抓取拉钩网关于python的招聘](chapter06/10.md)

* [第七章:爬虫的高级](chapter07/0.md)

* [第八章:scrapy框架的基本使用](chapter08/0.md)
  * [1.scrapy的安装](chapter08/01.md)
  * [2.scrapy的介绍](chapter08/02.md)
  * [3.twisted的认识](chapter08/03.md)
  * [4.scrapy项目基本配置及常用命令](chapter08/04.md)
  * [5.scrapy自定义命令](chapter08/05.md)
  * [6.选择器的使用](chapter08/06.md)
  * [7.Item和ItemLoader的使用](chapter08/07.md)
  * [8.spider的理解](chapter08/08.md)Î
  * [9.pipelines的使用](chapter08/09.md)Î
  * [10.在scrapy框架中数据存储](chapter08/10.md)Î
  * [11.分页功能抓取数据](chapter08/11.md)Î
  * [12.craw母模板爬虫](chapter08/12.md)Î
  * [13.关于Requests与Response的认识](chapter08/13.md)
  * [14.使用scrapy进行模拟登录(一)](chapter08/14.md)
  * [15.使用scrapy进行模拟登录(二)](chapter08/15.md)
  * [16.使用scrapy下载图片](chapter08/16.md)

* [第九章:scrapy框架的高级使用](chapter09/0.md)
  * [1.spider middleware(spider中间件)的认识](chapter09/01.md)
  * [2.downloader middleware(下载中间件)的认识](chapter09/02.md)
  * [3.自己编写下载中间件](chapter09/03.md)
  * [4.突破反爬虫策略](chapter09/04.md)
  * [5.搭建本地代理IP池](chapter09/05.md)
  * [6.设置动态请求头](chapter09/06.md)
  * [7.scrapy框架使用selenium抓取数据](chapter09/07.md)
  * [8.scrapy框架使用无界面浏览器抓取数据](chapter09/08.md)

* [第十章:scrapy-redis构建分布式爬虫](chapter10/0.md)
  * [1.redis的认识](chapter10/01.md)
  * [2.scrapy-redis架构](chapter10/02.md)
  * [3.scrapy-redis分布式爬虫](chapter10/03.md)
  * [4.使用分布式爬虫抓取珍爱网交友信息](chapter10/04.md)
  * [5.数据持久化](chapter10/05.md)

* [第十一章:移动端数据的抓取](chapter12/0.md)
