## <center>scrapy的介绍</center>


### 一、关于`scrapy`的介绍

![scrapy架构图](./source/images/scrapy架构图.png)

* 1、`Scrapy Engine`(引擎):`Scrapy`框架的核心部分。负责在`Spider`和`ItemPipeline`、`Downloader`、`Scheduler`中间通信、传递数据等。
* 2、`Spider`(爬虫):发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。<font color="#f00">这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的,都是由程序员自己决定</font>。
* 3、`Scheduler`(调度器):负责接收引擎发送过来的请求,并按照一定的方式进行排列和整理,负责调度请求的顺序等。
* 4、`Downloader`(下载器):负责接收引擎传过来的下载请求,然后去网络上下载对应的数据再交还给引擎。
* 5、`Item Pipeline`(管道):负责将`Spider`(爬虫）提取出来的`Item`(典型的处理数据)。
* 6、`Downloader Middlewares`(下载中间件):下载器中间件是在引擎及下载器之间特定的钩子,处理`Spider`的输入和输出,可以扩展下载器和引擎之间通信功能的中间件。
* 7、`Spider Middlewares`(`Spider`中间件):`Spider`中间件是在引擎及`Spider`之间的特定钩子,处理`Spider`的输入和输出,可以扩展引擎和爬虫之间通信功能的中间件。

### 二、关于`scrapy`的数据流

![流程图](./source/images/流程图.jpg)

  `Scrapy`引擎会将爬虫文件中设置的要爬取的起始网址(默认在`start_urls`属性中设置),传递到调度器中,随后进行图中1-13过程

* 1、第一步:过程(1)中主要将下一次要爬取的网址传递给`Scrapy`引擎,调度器是一个优先队列,里面存储起来多个要爬取的网址(也可以是单个),调度器会根据各网址的优先级传递给`Scrapy`引擎。
* 2、第二步:`Scrapy`引擎收到过程(1)中传递过来的网址之后,过程(2)`Scrapy`引擎主要将网址传递给下载中间件。
* 3、第三步:下载中间件收到`Scrapy`引擎传递过来的网址之后,过程(3)中下载中间件会将对应的网址传递给下载器
* 4、第四步:下载器收到对应要下载的网址,过程(4)会向互联网中对应的网址发送`request`请求,进行网页的下载。
* 5、第五步:互联网中对应的网址接收到`request`请求后,会有相应的`response`响应,随后响应传给下载中间件。
* 6、第六步:下载器接收到响应之后,即完成了对应网页的下载,随后过程(6)会将对应的响应传送给下载中间件。
* 7、第七步:下载中间件接收到对应响应之后,会与`Scrapy`引擎进行通信,过程(7)会将对应的`response`响应传递给`Scrapy`引擎。
* 8、第八步:`Scrapy`引擎接收到`response`响应之后,过程(8)`Scrapy`引擎会将`response`响应信息传递给爬虫中间件
* 9、第九步:爬虫中间件接收到对应响应之后,过程(9)爬虫中间件会将响应传递给对应的爬虫进行处理
* 10、第十步:爬虫就那些处理之后,大致会有两方面信息:**提取出来的数据和新的请求信息**,过程(10)爬虫会将处理后的信息传递给爬虫中间件。
* 11、第十一步:爬虫中间件接收到对应信息后,过程(11)会将对应的信息传递到`Scrapy`引擎。
* 12、第十二步:`Scrapy`引擎接收到爬虫处理后的信息之后,会同事进行过程(12)和过程(13),在过程(12)中`Scrapy`引擎会将提取出来的项目实体(`Item`)传递给实体管道(`ItemPipeline`),由于实体管道对提取出来的信息进行进一步处理
* 13、第十三步:`Scrapy`引擎会将爬虫处理后得到的请求信息传递给调度器,由调度器进行进一步网址的调度。
