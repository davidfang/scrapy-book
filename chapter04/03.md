### <center>数据存储到mysql数据库中</center>


### 一、如果你对`mysql`数据库还不太熟悉,可以[参考](https://kuangshp1.gitbooks.io/python-base/content/chapter10/0.html)

### 二、基本操作

* 1、在`python`中使用`pymysql`连接`mysql`
* 2、安装包

  ```py
  pip3 install pymysql
  ```

* 3、定义一个创建数据库的方法(或者手动、SQL语句创建数据库)

  ```py
  # 定义一个创建数据库的函数
  def create_table():
      # 创建数据库连接
      db = pymysql.connect(host='127.0.0.1', user='root', passwd='root', db='nodejs', port=3306,
                           charset='utf8')

      # 获取数据库句柄
      cursor = db.cursor()

      cursor.execute('DROP TABLE IF EXISTS food')
      # 创建article表的sql语句
      sql = """
          create table if not exists food(
            id INT NOT NULL AUTO_INCREMENT,
            name VARCHAR(50) ,
            price FLOAT,
            address VARCHAR(100),
            time DATE,
            PRIMARY KEY (`id`)
          )
      """

      try:
          # 执行sql语句
          cursor.execute(sql)
          # 提交事务
          db.commit()
          print('创建表成功')
      except pymysql.Error as e:
          # 数据回滚
          db.rollback()
          print(e)
      finally:
          if db:
              db.close()
  ```

### 三、爬取的数据存入到数据库中

* 1、依然使用之前抓取农产品的爬虫数据
* 2、在类中新增插入数据库的方法

  ```py
  def insert_table(self, name, price, address, time):
      """
      对爬取的数据插入到数据库中
      :param price:
      :param address:
      :param time:
      :return:
      """
      # 创建数据库连接
      db = pymysql.connect(host='127.0.0.1', user='root', passwd='root', db='nodejs', port=3306,
                           charset='utf8')

      # 获取数据库句柄
      cursor = db.cursor()

      # 插入数据的sql语句
      sql = 'insert into food (name, price, address, time) values (%s, %s, %s, %s)'
      try:
          # 执行 sql 语句
          value = (name, price, address, time)
          cursor.execute(sql, value)
          # 提交事务
          db.commit()
          return True
      except BaseException as e:  # 如果发生错误则回滚
          db.rollback()
          print(e)
      finally:  # 关闭游标连接
          cursor.close()
          # 关闭数据库连接
          db.close()
  ```
